---
title: "Gaussian Processes"
author: "Robin Aldridge-Sutton"
date: "07/05/2022"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

A Gaussian process (GP) is stochastic process (a distribution over functions) such that for any finite set of input values the function values have a multivariate Gaussian distribution, e.g. for $\mathbf{x} \in \mathbb{R}^d,$

$$f(\mathbf{x}) \sim N(\mu(\mathbf{x}) = \mathbf{0}, \Sigma = K(\mathbf{x}, \mathbf{x})),$$
$$K(\mathbf{x}, \mathbf{x}')_{i, j} = \sigma_f^2 \exp\left(\frac{(x_i - x'_j)^2}{2 l^2} \right).$$

```{r}
# Functions to sample from and predict values of a Gaussian process.
source("GP funcs.R")

# Plot samples from a GP
plot_GP_samps(
  l = 0.1, # Length scale
  sigma_f = 1, # Function standard deviation
  n_samps = 3 # Number of samples
)
```

## Gaussian process regression

A GP can be used as a functional prior.  The posterior is then the conditional distribution of functions given observations at a set of input values.  If the observations are assumed to include some Gaussian noise this is another GP, e.g.

$$\mathbf{y} = f(\mathbf{x}) + \epsilon,$$
$$f(\mathbf{x}) \sim N(\mu(\mathbf{x}) = \mathbf{0}, \Sigma = K(\mathbf{x}, \mathbf{x})),$$
$$ \epsilon \sim N(0, \sigma_n^2 I_d),$$
$$\implies f(\mathbf{x}')|\mathbf{y}(\mathbf{x}) \sim N(\mu(\mathbf{x}'), \Sigma),$$
$$\mu(\mathbf{x}') = K(\mathbf{x}', \mathbf{x}) [K(\mathbf{x}, \mathbf{x}) + \sigma_n^2 I_d]^{-1} \mathbf{y}(\mathbf{x}),$$
$$\Sigma = K(\mathbf{x}', \mathbf{x}') - K(\mathbf{x}', \mathbf{x}) [K(\mathbf{x}, \mathbf{x}) + \sigma_n^2 I_d]^{-1} K(\mathbf{x}, \mathbf{x}').$$

```{r}
plot_GP_regression(
  n_obs = 5, # Number of points to observe
  l = 0.1, # Length scale
  sigma_f = 1, # Function standard deviation
  sigma_n = 0.1 # Noise standard deviation
)
```

There are various methods of model selection and hyper-parameter tuning.

